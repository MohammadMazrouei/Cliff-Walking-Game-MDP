{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nessary libraries\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.cliffwalking import CliffWalkingEnv\n",
    "from gymnasium.error import DependencyNotInstalled\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this class\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "image_path = path.join(path.dirname(gym.__file__), \"envs\", \"toy_text\")\n",
    "\n",
    "class CliffWalking(CliffWalkingEnv):\n",
    "    def __init__(self, is_hardmode=True, num_cliffs=10, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.is_hardmode = is_hardmode\n",
    "\n",
    "        # Generate random cliff positions\n",
    "        if self.is_hardmode:\n",
    "            self.num_cliffs = num_cliffs\n",
    "            self._cliff = np.zeros(self.shape, dtype=bool)\n",
    "            self.start_state = (3, 0)\n",
    "            self.terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "            self.cliff_positions = []\n",
    "            while len(self.cliff_positions) < self.num_cliffs:\n",
    "                new_row = np.random.randint(0, 4)\n",
    "                new_col = np.random.randint(0, 11)\n",
    "                state = (new_row, new_col)\n",
    "                if (\n",
    "                    (state not in self.cliff_positions)\n",
    "                    and (state != self.start_state)\n",
    "                    and (state != self.terminal_state)\n",
    "                ):\n",
    "                    self._cliff[new_row, new_col] = True\n",
    "                    if not self.is_valid():\n",
    "                        self._cliff[new_row, new_col] = False\n",
    "                        continue\n",
    "                    self.cliff_positions.append(state)\n",
    "\n",
    "        # Calculate transition probabilities and rewards خانه صخره قرار گیرد امتیاز -100 لحاظ\n",
    "\n",
    "        self.P = {}\n",
    "        for s in range(self.nS):\n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            self.P[s] = {a: [] for a in range(self.nA)}\n",
    "            self.P[s][UP] = self._calculate_transition_prob(position, [-1, 0])\n",
    "            self.P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1])\n",
    "            self.P[s][DOWN] = self._calculate_transition_prob(position, [1, 0])\n",
    "            self.P[s][LEFT] = self._calculate_transition_prob(position, [0, -1])\n",
    "\n",
    "    def _calculate_transition_prob(self, current, delta):\n",
    "        new_position = np.array(current) + np.array(delta)\n",
    "        new_position = self._limit_coordinates(new_position).astype(int)\n",
    "        new_state = np.ravel_multi_index(tuple(new_position), self.shape)\n",
    "        if self._cliff[tuple(new_position)]:\n",
    "            return [(1.0, self.start_state_index, -100, False)]\n",
    "\n",
    "        terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "        is_terminated = tuple(new_position) == terminal_state\n",
    "        return [(1 / 3, new_state, -1, is_terminated)]\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(self):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((3, 0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r, c) in discovered:\n",
    "                discovered.add((r, c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= self.shape[0] or c_new < 0 or c_new >= self.shape[1]:\n",
    "                        continue\n",
    "                    if (r_new, c_new) == self.terminal_state:\n",
    "                        return True\n",
    "                    if not self._cliff[r_new][c_new]:\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    def step(self, action):\n",
    "        if action not in [0, 1, 2, 3]:\n",
    "            raise ValueError(f\"Invalid action {action}   must be in [0, 1, 2, 3]\")\n",
    "\n",
    "        if self.is_hardmode:\n",
    "            match action:\n",
    "                case 0:\n",
    "                    action = np.random.choice([0, 1, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 1:\n",
    "                    action = np.random.choice([0, 1, 2], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 2:\n",
    "                    action = np.random.choice([1, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 3:\n",
    "                    action = np.random.choice([0, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "\n",
    "        return super().step(action)\n",
    "\n",
    "    def _render_gui(self, mode):\n",
    "        try:\n",
    "            import pygame\n",
    "        except ImportError as e:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gymnasium[toy-text]`\"\n",
    "            ) from e\n",
    "        if self.window_surface is None:\n",
    "            pygame.init()\n",
    "\n",
    "            if mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                pygame.display.set_caption(\"CliffWalking - Edited by Audrina & Kian\")\n",
    "                self.window_surface = pygame.display.set_mode(self.window_size)\n",
    "            else:  # rgb_array\n",
    "                self.window_surface = pygame.Surface(self.window_size)\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "        if self.elf_images is None:\n",
    "            hikers = [\n",
    "                path.join(image_path, \"img/elf_up.png\"),\n",
    "                path.join(image_path, \"img/elf_right.png\"),\n",
    "                path.join(image_path, \"img/elf_down.png\"),\n",
    "                path.join(image_path, \"img/elf_left.png\"),\n",
    "            ]\n",
    "            self.elf_images = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in hikers\n",
    "            ]\n",
    "        if self.start_img is None:\n",
    "            file_name = path.join(image_path, \"img/stool.png\")\n",
    "            self.start_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.goal_img is None:\n",
    "            file_name = path.join(image_path, \"img/cookie.png\")\n",
    "            self.goal_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.mountain_bg_img is None:\n",
    "            bg_imgs = [\n",
    "                path.join(image_path, \"img/mountain_bg1.png\"),\n",
    "                path.join(image_path, \"img/mountain_bg2.png\"),\n",
    "            ]\n",
    "            self.mountain_bg_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in bg_imgs\n",
    "            ]\n",
    "        if self.near_cliff_img is None:\n",
    "            near_cliff_imgs = [\n",
    "                path.join(image_path, \"img/mountain_near-cliff1.png\"),\n",
    "                path.join(image_path, \"img/mountain_near-cliff2.png\"),\n",
    "            ]\n",
    "            self.near_cliff_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in near_cliff_imgs\n",
    "            ]\n",
    "        if self.cliff_img is None:\n",
    "            file_name = path.join(image_path, \"img/mountain_cliff.png\")\n",
    "            self.cliff_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            row, col = np.unravel_index(s, self.shape)\n",
    "            pos = (col * self.cell_size[0], row * self.cell_size[1])\n",
    "            check_board_mask = row % 2 ^ col % 2\n",
    "            self.window_surface.blit(self.mountain_bg_img[check_board_mask], pos)\n",
    "\n",
    "            if self._cliff[row, col]:\n",
    "                self.window_surface.blit(self.cliff_img, pos)\n",
    "            if s == self.start_state_index:\n",
    "                self.window_surface.blit(self.start_img, pos)\n",
    "            if s == self.nS - 1:\n",
    "                self.window_surface.blit(self.goal_img, pos)\n",
    "            if s == self.s:\n",
    "                elf_pos = (pos[0], pos[1] - 0.1 * self.cell_size[1])\n",
    "                last_action = self.lastaction if self.lastaction is not None else 2\n",
    "                self.window_surface.blit(self.elf_images[last_action], elf_pos)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.window_surface)), axes=(1, 0, 2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment\n",
    "env = CliffWalking(render_mode=\"human\")\n",
    "observation, info = env.reset(seed=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP:\n",
    "    def __init__(self, max_iterations, discount_factor, cliff_positions):\n",
    "        self.tmp_V = np.zeros((4, 12))\n",
    "        self.V = np.zeros((4, 12))\n",
    "        self.Q = np.zeros((4, 12, 4))\n",
    "        self.pi = np.zeros((4, 12), dtype=int)\n",
    "        self.max_iter = max_iterations\n",
    "        self.gama = discount_factor\n",
    "        self.cliffs = cliff_positions\n",
    "\n",
    "    def reward(self, state):\n",
    "        if tuple(state) in self.cliffs:\n",
    "            return -100\n",
    "        elif tuple(state) == (3, 11):\n",
    "            return 10000\n",
    "        else:\n",
    "            return -5\n",
    "\n",
    "    def update_QV(self):\n",
    "        di = [-1, 0, 1, 0]\n",
    "        dj = [0, 1, 0, -1]\n",
    "        for i in range(4):\n",
    "            for j in range(12):\n",
    "                for k in range(4):\n",
    "                    self.Q[i, j, k] = 0\n",
    "                    for action in [UP, RIGHT, DOWN, LEFT]:\n",
    "                        if k != action and action%2 == k%2:\n",
    "                            continue\n",
    "                        next_state = (i+di[action], j+dj[action])\n",
    "                        if next_state[0] >= 4 or next_state[1] >= 12 or next_state[0] < 0 or next_state[1] < 0:\n",
    "                            continue\n",
    "                        self.Q[i, j, k] = self.Q[i, j, k] + (1/3*( (-1) + self.gama*self.V[next_state[0], next_state[1]]))\n",
    "                        \n",
    "         \n",
    "        for i in range(4):\n",
    "            for j in range(12):\n",
    "                if i == 3 and j == 11:\n",
    "                    continue\n",
    "                if (i, j) in self.cliffs:\n",
    "                    continue\n",
    "                self.V[i, j] = max(self.Q[i, j])\n",
    "                    \n",
    "                    \n",
    "    def update_pi(self):\n",
    "        for i in range(4):\n",
    "            for j in range(12):\n",
    "                for action in [UP, RIGHT, DOWN, LEFT]:\n",
    "                    if self.Q[i, j, action] == self.V[i, j]:\n",
    "                        self.pi[i, j] = action\n",
    "\n",
    "\n",
    "\n",
    "    def check_convergence(self):\n",
    "        return self.tmp_V.all() == self.V.all()\n",
    "\n",
    "    def run(self):\n",
    "        iter_cnt = 0\n",
    "        converged = 0\n",
    "        convergance_num = 1000\n",
    "        self.V[3, 11] = 10000\n",
    "        for ci, cj in self.cliffs:\n",
    "            self.V[ci, cj] = -100\n",
    "        while iter_cnt < self.max_iter:\n",
    "            #print(self.V, self.tmp_V, sep='\\n')\n",
    "            self.update_QV()\n",
    "            if self.check_convergence():\n",
    "                converged += 1\n",
    "            else:\n",
    "                converged = 0\n",
    "\n",
    "            iter_cnt += 1\n",
    "        print(iter_cnt)\n",
    "        self.update_pi()\n",
    "        print(self.pi); print()\n",
    "        print(self.V); print()\n",
    "        print(self.Q)\n",
    "\n",
    "            \n",
    "    def policy(self, state):\n",
    "        return self.pi[state[0], state[1]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[[0 1 0 0 0 0 3 0 1 3 0 1]\n",
      " [2 3 0 0 0 0 0 3 0 0 2 3]\n",
      " [3 3 0 0 1 3 0 1 2 3 0 1]\n",
      " [3 3 2 3 0 1 2 0 0 0 2 0]]\n",
      "\n",
      "[[-1.00000000e+02 -2.17874804e+00 -1.88301840e+00 -1.87575772e+00\n",
      "  -2.14728512e+00 -3.05963713e+00 -5.82928307e+00 -1.00000000e+02\n",
      "  -4.38095238e+01 -4.38095238e+01 -1.00000000e+02  6.55844749e+01]\n",
      " [-2.07145939e+00 -3.15725286e+00 -3.79474140e+00 -4.27553341e+00\n",
      "  -5.24794558e+00 -7.73700008e+00 -1.41490842e+01 -3.02639976e+01\n",
      "  -1.00000000e+02 -1.00000000e+02  4.91780822e+00  2.19726027e+02]\n",
      " [-1.52538954e+00 -2.94063542e+00 -1.00000000e+02 -1.00000000e+02\n",
      "  -3.71164630e+01 -1.51402645e+01 -1.00000000e+02  1.66024255e+01\n",
      "   5.19025069e+01  5.93141958e+01 -1.00000000e+02  6.65251142e+02]\n",
      " [-7.90950196e-01 -1.78614235e+00 -1.14313290e+01 -3.40960654e+01\n",
      "  -1.00000000e+02 -2.28075187e+00  9.75998048e+00  3.70362423e+01\n",
      "   1.00425069e+02  2.49144812e+02  6.74076777e+02  2.00000000e+03]]\n",
      "\n",
      "[[[ -0.98695775  -1.9417289   -1.9417289   -0.95477115]\n",
      "  [-31.23157219  -2.17874804 -32.51208138 -31.61384252]\n",
      "  [ -1.8830184   -2.3678164   -3.35477415  -2.4587135 ]\n",
      "  [ -1.87575772  -2.59351223  -3.49175108  -2.51423221]\n",
      "  [ -2.14728512  -3.15894148  -4.05500213  -2.80377766]\n",
      "  [ -3.05963713  -4.73655161  -5.71407048  -3.63195223]\n",
      "  [-31.5845578  -34.91139194 -36.16261641  -5.82928307]\n",
      "  [-15.55830873 -22.8887231  -24.97084135 -11.49465087]\n",
      "  [-43.80952381 -43.80952381 -74.14285714 -60.66666667]\n",
      "  [-43.80952381 -60.66666667 -74.14285714 -43.80952381]\n",
      "  [  5.86581866  20.48401826   7.00782779 -12.33418134]\n",
      "  [-30.33333333  65.58447489  35.25114155  35.25114155]]\n",
      "\n",
      " [[-31.61384252 -32.40479272  -2.07145939 -31.12428353]\n",
      "  [ -3.41348465  -3.67423746  -3.64205086  -3.15725286]\n",
      "  [ -3.7947414  -32.84756554 -33.22983588 -32.51208138]\n",
      "  [ -4.27553341 -33.13711099 -33.7128061  -32.70114974]\n",
      "  [ -5.24794558 -15.10022447 -15.73869896 -14.06178447]\n",
      "  [ -7.73700008 -10.70469576 -11.36118829  -8.03435416]\n",
      "  [-14.14908423 -41.82798421 -42.40029931 -35.06988495]\n",
      "  [-65.24472527 -56.01927235 -30.26399762 -30.26399762]\n",
      "  [-53.22205643 -28.57210506 -24.5084472   -7.65130434]\n",
      "  [-42.66751468   5.12674407 -11.73039879 -26.3485984 ]\n",
      "  [  4.91780822   4.91780822   4.91780822 -91.        ]\n",
      "  [ 20.48401826 218.58401826 200.38401826 219.7260274 ]]\n",
      "\n",
      " [[ -2.17029511  -2.7409135   -1.78614235  -1.52538954]\n",
      "  [-32.40479272 -32.48301856 -31.99345957  -2.94063542]\n",
      "  [-33.02061305 -35.56782111 -35.31158932  -6.45001174]\n",
      "  [-43.41759893 -23.64641854 -52.36375852 -42.51147963]\n",
      "  [-37.11646302 -37.11646302 -65.54207935 -62.57438368]\n",
      "  [-44.45603893 -34.00532559 -42.81916447 -15.14026449]\n",
      "  [ -4.80607697   2.66399652   2.36664245  -6.85881048]\n",
      "  [-24.5084472   16.6024255   -4.31837521 -28.96832658]\n",
      "  [ -8.22501361  16.9217793   51.90250695   4.1082482 ]\n",
      "  [-45.42924792  13.74344372  59.31419581  59.31419581]\n",
      "  [217.84494367 402.27371805 418.59263433 220.49263433]\n",
      "  [ 35.25114155 665.25114155 569.33333333 634.91780822]]\n",
      "\n",
      " [[ -1.66012623  -1.66012623  -0.86917604  -0.7909502 ]\n",
      "  [ -5.54887438  -4.97825599  -4.33335042  -1.78614235]\n",
      "  [-41.76466231 -40.89548627 -11.43132898 -31.20250937]\n",
      "  [-64.42939869 -60.66666667 -34.09606536 -34.09606536]\n",
      "  [-23.04798408 -12.48583114 -11.57971184 -22.03042518]\n",
      "  [-32.61408521  -2.28075187 -27.73867252 -35.20874601]\n",
      "  [-20.57335286 -19.55579396   9.75998048 -31.35089223]\n",
      "  [ 37.03624235  34.44158154  32.38884803   7.24205513]\n",
      "  [100.42506851  89.64752914  85.18764976  26.01495812]\n",
      "  [249.14481241 219.35062519 231.683887    47.25511263]\n",
      "  [643.74344372 569.33333333 674.07677706  44.07677706]\n",
      "  [401.13170892 199.24200913 201.88969978 401.13170892]]]\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Perform the action and receive feedback from the environment\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m next_state, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m current_state \u001b[38;5;241m=\u001b[39m (next_state\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m12\u001b[39m, next_state\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[0;32mIn[7], line 92\u001b[0m, in \u001b[0;36mCliffWalking.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     90\u001b[0m             action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], p\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/gymnasium/envs/toy_text/cliffwalking.py:181\u001b[0m, in \u001b[0;36mCliffWalkingEnv.step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastaction \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(s), r, t, \u001b[38;5;28;01mFalse\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m: p})\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/gymnasium/envs/toy_text/cliffwalking.py:206\u001b[0m, in \u001b[0;36mCliffWalkingEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 177\u001b[0m, in \u001b[0;36mCliffWalking._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    175\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[1;32m    176\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# rgb_array\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    180\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_surface)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    181\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the maximum number of iterations\n",
    "max_iter_number = 1000\n",
    "\n",
    "mdp = MDP(1000, 0.9, env.cliff_positions)\n",
    "mdp.run()\n",
    "\n",
    "current_state = (3, 0)\n",
    "for __ in range(max_iter_number):\n",
    "    # TODO: Implement the agent policy here\n",
    "    # Note: .sample() is used to sample random action from the environment's action space\n",
    "\n",
    "    # Choose an action (Replace this random action with your agent's policy)\n",
    "    action = mdp.policy(current_state)\n",
    "    print(action)\n",
    "\n",
    "    # Perform the action and receive feedback from the environment\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    current_state = (next_state//12, next_state%12)\n",
    "\n",
    "    if done or truncated:\n",
    "        observatistopon, info = env.reset()\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
